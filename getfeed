#!/usr/bin/env python2
__version__ = "0.2.1_alpha1+"
__license__ = "BSD-4"
__author__ = "Sergei Shilovsky <triumhiz@yandex.ru>"

import sys
import datetime
from os import path
import argparse
import subprocess
import sqlite3

import yaml
import xdg.BaseDirectory as xdgbase
import feedparser

DEFAULT_CONFIG = "config.yaml"
PROJECT_NAME = "getfeed"
LAST_MESSAGE_VERSION = 0
LAST_FEED_VERSION = 0

NONE_NAME = "none"
DEFAULT_NAME = "default"

DROP_NONE = {"command":"true"}
DROP_DEFAULT = {"command":"tee -a /tmp/getfeed.log"}

CACHE_NONE = {}
CACHE_DEFAULT = {"host":"cache.db"}

DEFAULT_HEADER_TEMPLATES = {
        "From":"{0}@localhost".format(PROJECT_NAME),
        "Subject":"{e.title}",
        }
DEFAULT_BODY_TEMPLATE = "{e.summary}"

def err(msg):
    print >> sys.stderr, "ERROR: ", msg
    exit(255)

def warn(msg):
    print >> sys.stderr, "WARNING: ", msg

def info(msg):
    print >> sys.stderr, "INFO: ",msg

### Configuration parsing

def get_config(configfile=None):
    if configfile is None:
        configfile = DEFAULT_CONFIG

    in_configfile = configfile
    
    if path.sep not in configfile:
        configfile = xdgbase.load_first_config(PROJECT_NAME,configfile)

    if configfile is None:
        warn('File "%s" not found'%in_configfile)
    
    try:
        f = None
        f = open(configfile)
        return yaml.load(f)
    except:
        warn('Error loading/parsing "%s"'%in_configfile)
    finally:
        if f is not None:
            f.close()

def extract_records(config,key,req_type):
    # TODO normal error and warning messages
    l = config.get(key)
    t = type(l)
    if t is not req_type and l is not None:
        err('%s expected for "%s" key'%(req_type.__name__,key))
    if l is None or len(l) == 0:
        warn('empty %s for "%s" key'%(req_type.__name__,key))

    return l

def parse_config(config):
    if config is None:
        return
    if type(config) is not dict:
        err('Config file is not a dictionary')

    drops = extract_records(config,'drops',dict) or {}
    drops.setdefault(DEFAULT_NAME, DROP_DEFAULT)
    drops.setdefault(NONE_NAME, DROP_NONE)

    caches = extract_records(config,'caches',dict) or {}
    caches.setdefault(DEFAULT_NAME, CACHE_DEFAULT)
    caches.setdefault(NONE_NAME, CACHE_NONE)

    feeds = extract_records(config,'feeds',list) or {}

    # TODO revise
    for i, feed in enumerate(feeds,start=1):
        if type(feed) is not dict:
            err('dict expected for feeds record element')

        drop_name = feed.get('drop','default')
        drop = drops.get(drop_name,None)
        if drop is None:
            drop = NONE_NAME
            warn(('Drop record "%s" for feed #%s not found.\n'+
                'Supposing "%s"')
                    % (drop_name, i, NONE_NAME))
        feed["drop"] = drop

        cache_name = feed.get('cache','default')
        cache = caches.get(cache_name, None)
        if cache is None:
            warn(('Cache record "%s" for feed #%s not found.\n'+
                'Supposing "%s"')
                    % (cache_name, i, NONE_NAME))
            cache = NONE_NAME
        feed["cache"] = cache

        yield feed
   

### Arguments parsing
argparser = argparse.ArgumentParser(description=
        'RSS/Atom feed fetcher and piper')
argparser.add_argument('--version',action='version',
        version='%(prog)s '+__version__)
argparser.add_argument('--rcfile','-r',action='append',
        help='use this config file instead of default one. '+
        'You may use this option more than once.')

def main():
    global ctime
    args = argparser.parse_args()
    rcfiles = args.rcfile
    if rcfiles is None or len(rcfiles) == 0:
        rcfiles = (None,)

    for rc in rcfiles:
        conf = get_config(rc)
        feeds = parse_config(conf)
        for feed in feeds:
            process_feed(feed)

### Feed parsing

def process_feed(feed_conf):
    url = feed_conf.get('url')
    if url is None:
        warn("Feed without URL specified")
        return

    feed = feedparser.parse(url)

    drop = feed_conf.get('drop')
    drop_command = drop.get('command')

    cache = feed_conf.get('cache')
    if 'connection' not in cache:
        connection = cache['connection'] = init_database(cache)
    else:
        connection = cache['connection']
    if connection is not None:
        feed['dbid'] = get_feed_dbid(cache, feed)
        feed['ctime'] = datetime.datetime.now()

    body_template = feed_conf.get('body',DEFAULT_BODY_TEMPLATE)
    header_templates = feed_conf.get('headers',{})
    for i,j in DEFAULT_HEADER_TEMPLATES.items():
        header_templates.setdefault(i, j)

    for entry in feed['entries']:
        hashes = message_hash(feed,entry)
        if hash_cached(cache, feed, hashes):
            continue
        
        patterns = {
                'e': entry,
                'f': feed,
                }
        
        headers = {}
        for header, template in header_templates.items():
            template = template.decode()
            headers[header] = template.format(**patterns)

        body_template = body_template.decode()
        body = body_template.format(**patterns)

        message = u"{headers}\n{body}\n".format(
                body = body,
                headers = u''.join((
                    u'{header}: {value}\n'.format(
                        header=header,
                        value=value)
                    for header, value in headers.items()
                )))

        mda = subprocess.Popen(drop_command, shell=True, stdin=subprocess.PIPE)
        message = message.encode('utf-8')
        mda.stdin.write(message)
        mda.stdin.close()
        ret = mda.wait()
        if ret != 0:
            err('Error in dropper')
        cache_hash(cache, feed, hashes)


### Caching
def init_database(cache_conf):
    host = cache_conf.get('host',None)
    if host is None:
        return
    host = get_cache_file(host)
    db = sqlite3.connect(host)
    cur = db.cursor()
    #cur.execute("""CREATE TABLE IF NOT EXISTS meta (
    #id int PRIMARY KEY,
    #version int
    #)""")
    cur.execute("""CREATE TABLE IF NOT EXISTS feeds (
    id int PRIMARY KEY,
    version int,
    hash int,
    UNIQUE(version, hash)
    )""")
    cur.execute("""CREATE TABLE IF NOT EXISTS messages (
    feed int,
    version int,
    hash int,
    ctime datetime,
    FOREIGN KEY(feed) REFERENCES feeds(id),
    PRIMARY KEY(feed, version, hash)
    )""")
    db.commit()
    cur.close()
    return db


def get_cache_file(cachefile=None):
    in_cachefile = cachefile
    
    if path.sep not in cachefile:
        dir = xdgbase.save_data_path(PROJECT_NAME)
        cachefile = path.join(dir,cachefile)

    if cachefile is None:
        warn('File "%s" not found'%in_configfile)
    
    return cachefile


def message_hash(feed, message):
    # TODO edit hash function
    hashes = []
    # Version 0
    hashes.append(hash(message.title) ^ hash(message.summary))

    return hashes


def feed_hash(feed):
    hashes = []
    # Version 0
    hashes.append(hash(feed['url']))

    return hashes


def get_feed_dbid(cache, feed):
        # TODO feed hash versions
    hash = feed_hash(feed)[0]
    connection = cache.get('connection',None)
    if connection is None:
        return False
    cur = connection.cursor()
    try:
        cur.execute("""SELECT id FROM feeds WHERE hash = ?""", (hash,))
        for row in cur:
            return row[0]
        cur.execute("""SELECT MAX(id) FROM feeds""")
        max = ((cur.fetchone() or 0)[0] or 0)+ 1
        cur.execute("""INSERT INTO feeds (id, version, hash)
                VALUES (?, ?, ?)""", (max, LAST_FEED_VERSION, hash))
        return max
    except:
        connection.rollback()
        raise
    finally:
        cur.close()
        connection.commit()


def hash_cached(cache, feed, hashes):
    connection = cache.get('connection',None)
    if connection is None:
        return False
    cur = connection.cursor()
    try:
        for version, hash in enumerate(hashes):
            cur.execute("""SELECT COUNT(*) FROM messages WHERE
                feed = ? AND version = ? AND hash = ?""",
                (feed['dbid'], version, hash))
            result = cur.fetchone()[0]
            if result >= 1:
                return True

        return False
    except:
        connection.rollback()
        raise
    finally:
        cur.close()
        connection.commit()


def cache_hash(cache, feed, hashes):
    connection = cache.get('connection',None)
    if connection is None:
        return False
    cur = connection.cursor()
    try:
        cur.execute("""INSERT INTO messages (feed, version, hash, ctime)
        VALUES (?, ?, ?, ?)""", (feed['dbid'],
            LAST_MESSAGE_VERSION, hashes[LAST_MESSAGE_VERSION], feed['ctime']))
    except:
        connection.rollback()
        raise
    finally:
        cur.close()
        connection.commit()

if __name__ == '__main__':
    main()

